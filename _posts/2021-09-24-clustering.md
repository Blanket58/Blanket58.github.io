---
layout: post
title: 聚类
date: 2021-09-24
tag: Algorithms
katex: true
---

## K-means

**原理：**

1. 首先随机从样本集中找K个点当作K个聚类簇的均值点
2. 计算所有样本点分别与各个均值点的距离，将样本点归入距离最小的簇中
3. 重新计算每个聚类簇的均值点位置
4. 重复操作，直至达到指定迭代次数、或临近两次迭代均值点的Frobenius范数变动小于阈值

> 其中Frobenius范数也称欧几里得范数，即矩阵中每个元素的平方和再开方。在这里矩阵指的是K行n列的质心矩阵，它的每一行为一个质心，每一列为该质心在各个维度上的坐标。
>

**优点：**

- 原理简单、实现容易、收敛速度快；
- 聚类效果较优；
- 算法的可解释性比较强；
- 主要需要调参的参数仅仅是簇数K。

**缺点：**

- K值的选取不好把握；
- 对于不是[凸的数据集](/2021/02/machine-learning/)比较难收敛；
- 如果各隐含类别的数据不平衡，比如各隐含类别的数据量严重失衡，或者各隐含类别的方差不同，则聚类效果不佳；
- 采用迭代方法，得到的结果只是局部最优；
- 它的决策边界一定是线性的，对于线性不可分的数据算法会失效，但可以通过使用一个核函数将数据向高维映射，使得数据在高维空间中变得线性可分。

## 层次聚类

**原理：**

试图在不同层次上对数据集进行划分，从而形成树形的聚类结构。数据集的划分可采用“自底向上”的聚合策略或“自顶向下”的拆分策略。聚合策略的过程如下：

1. 首先将样本集中的每个点都视为一个聚类簇
2. 计算各个聚类簇之间的距离，将距离最短的两个簇合并
3. 重复第二步操作，直至剩余K个簇

**优点：**

- 距离和规则的相似度容易定义，限制少；
- 不需要预先给定聚类簇数；
- 可以发现类的层次关系，用于生成概念、文档层次树等；
- 簇的大小可以不同；
- 可以聚类成任意形状。

**缺点：**

- 算法时间复杂度较大；
- 离群点能产生很大影响。

## DBSCAN

**原理：**

1. 首先定义四个概念：

   核心对象：在A的$\varepsilon$邻域内，至少有N个样本

   密度直达：B在A的$\varepsilon$邻域内，且A为核心对象，于是B由A密度直达

   密度可达：C由B密度直达，于是C由A密度可达

   密度相连：D由A密度直达，则C与D密度相连

2. 达到最大长度的密度相连簇个数即总簇数，每个簇由密度相连的核心对象与它们$\varepsilon$邻域内的样本点组成

**优点：**

- 可以处理任何形状的聚类簇，能够检测异常点。

**缺点：**

- 需要给定数据点的领域半径$\varepsilon$和最少样本数量N，对输入参数较敏感。

